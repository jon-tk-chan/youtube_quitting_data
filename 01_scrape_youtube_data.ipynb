{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a122011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "##### Author: Jonathan Chan\n",
    "##### \n",
    "##### ELI5: Access the google API to search pages of results, get stats_df, \n",
    "##### Refactor the youtube build variables\n",
    "#####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df848a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "import json\n",
    "import credentials\n",
    "\n",
    "# define the variables used to access the YouTube API\n",
    "DEVELOPER_KEY = credentials.GOOGLE_API_KEY\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "#Set the youtube search queries \n",
    "query=\"why I quit my tech job\"\n",
    "max_results=500\n",
    "order='relevance'\n",
    "\n",
    "#replace with \"data\" folder when doing full run - will use up Google API credits\n",
    "# max_results=1000\n",
    "# data_folder = \"data\"\n",
    "\n",
    "# Define the output folder to save the data\n",
    "data_folder = \"data\" \n",
    "# out_filepath =f\"{data_folder}/01_youtubeStatsTranscripts.json\"\n",
    "#setup category dict\n",
    "cat_dict = {\n",
    "    1: \"Film & Animation\",\n",
    "    2:\t\"Autos & Vehicles\",\n",
    "    10:\t\"Music\",\n",
    "    15:\"Pets & Animals\",\n",
    "    17:\t\"Sports\",\n",
    "    18:\t\"Short Movies\",\n",
    "    19:\t\"Travel & Events\",\n",
    "    20:\t\"Gaming\",\n",
    "    21:\t\"Videoblogging\",\n",
    "    22:\t\"People & Blogs\",\n",
    "    23:\t\"Comedy\",\n",
    "    24:\t\"Entertainment\",\n",
    "    25:\t\"News & Politics\",\n",
    "    26:\t\"Howto & Style\",\n",
    "    27:\t\"Education\",\n",
    "    28:\t\"Science & Technology\",\n",
    "    29:\t\"Nonprofits & Activism\",\n",
    "    30: \"Movies\",\n",
    "    31:\t\"Anime/Animation\",\n",
    "    32:\t\"Action/Adventure\",\n",
    "    33:\t\"Classics\",\n",
    "    34:\t\"Comedy\",\n",
    "    35:\t\"Documentary\",\n",
    "    36:\t\"Drama\",\n",
    "    37:\t\"Family\",\n",
    "    38:\t\"Foreign\",\n",
    "    39:\t\"Horror\",\n",
    "    40:\t\"Sci-Fi/Fantasy\",\n",
    "    41:\t\"Thriller\",\n",
    "    42:\t\"Shorts\",\n",
    "    43:\t\"Shows\",\n",
    "    44: \"Trailers\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a1d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Setup the YouTube API access using the variables listed above\n",
    "# youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3244639d-9f9a-4cf5-8420-e274867d47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n iterations: 10\n",
      "LENGTH OF VIDEO LIST: 500\n",
      "LENGTH OF VIDEO df: (500, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bVJfQAe-UP4</td>\n",
       "      <td>Why I Quit my 125k Analytics Job</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>2022-12-20T12:00:33Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-ayEjbg0ZEc</td>\n",
       "      <td>I QUIT MY JOB as a Financial Analyst to START ...</td>\n",
       "      <td>UChpxXPOP1xIq65mpNv-DclQ</td>\n",
       "      <td>2021-07-22T14:00:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9h0uhjdsOI</td>\n",
       "      <td>The REAL Reason I Quit My 6-Figure Data Analys...</td>\n",
       "      <td>UC0GmdVKZhMM3Rmielp4oVAA</td>\n",
       "      <td>2022-03-07T17:43:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sd5F1uR3tvA</td>\n",
       "      <td>I quit my 6-figure Data Analyst job in 4 month...</td>\n",
       "      <td>UCNXDU-8M1KFAWpFxmev8C-g</td>\n",
       "      <td>2024-03-23T11:22:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M8md7_gyBy4</td>\n",
       "      <td>I QUIT my $170,000 Tech Job After Learning 3 L...</td>\n",
       "      <td>UC0GmdVKZhMM3Rmielp4oVAA</td>\n",
       "      <td>2022-01-17T10:58:08Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title  \\\n",
       "0  bVJfQAe-UP4                   Why I Quit my 125k Analytics Job   \n",
       "1  -ayEjbg0ZEc  I QUIT MY JOB as a Financial Analyst to START ...   \n",
       "2  C9h0uhjdsOI  The REAL Reason I Quit My 6-Figure Data Analys...   \n",
       "3  sd5F1uR3tvA  I quit my 6-figure Data Analyst job in 4 month...   \n",
       "4  M8md7_gyBy4  I QUIT my $170,000 Tech Job After Learning 3 L...   \n",
       "\n",
       "                 channel_id          published_at  \n",
       "0  UC7cs8q-gJRlGwj4A8OmCmXg  2022-12-20T12:00:33Z  \n",
       "1  UChpxXPOP1xIq65mpNv-DclQ  2021-07-22T14:00:01Z  \n",
       "2  UC0GmdVKZhMM3Rmielp4oVAA  2022-03-07T17:43:04Z  \n",
       "3  UCNXDU-8M1KFAWpFxmev8C-g  2024-03-23T11:22:46Z  \n",
       "4  UC0GmdVKZhMM3Rmielp4oVAA  2022-01-17T10:58:08Z  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FUNCTIONAL VERSION OF v2\n",
    "\n",
    "def scrape_youtube_df(input_query=\"why I quit my job\"):\n",
    "    \"\"\" \n",
    "    Returns the youtube video query results based on the input_query. \n",
    "\n",
    "    assume youtube object was built using the build() function outside of this function\n",
    "    \"\"\"\n",
    "\n",
    "    #### Setup the YouTube API access using the variables listed above\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n",
    "    n_results = 0\n",
    "    n_iterations = max_results // 50 # get whole number of times we need to go through pages of youtube searches -\n",
    "    print(f\"n iterations: {n_iterations}\")\n",
    "\n",
    "    ### Initialize list of pages of results prior to searches\n",
    "    results_list = []\n",
    "    next_token = None\n",
    "    prev_token = None\n",
    "\n",
    "    #populate results_list with items searched from query - go through each page and update nextPageTokenm prevPageToken to iterate\n",
    "    for i in range(0, n_iterations):\n",
    "        search_response = youtube.search().list(\n",
    "            q=input_query, pageToken=next_token,maxResults=50, #only 50 results per page - verify?\n",
    "            type=\"video\", order = \"relevance\", part=\"id, snippet\", location=None,locationRadius=None).execute()\n",
    "        results_list.append(search_response)\n",
    "        #Update next_token and prev_token variables for next search iteration\n",
    "        if 'nextPageToken' in search_response.keys():\n",
    "            next_token=search_response['nextPageToken']\n",
    "        else:\n",
    "            next_token=None\n",
    "        if 'prevPageToken' in search_response.keys():\n",
    "            prev_token=search_response['prevPageToken']\n",
    "        else:\n",
    "            prev_token=None\n",
    "    #create list of dicts for youtube urls and basic info\n",
    "    video_list = []\n",
    "    for result in results_list:\n",
    "        curr_page = result['items']\n",
    "        for curr_vid in curr_page:\n",
    "            video_title=curr_vid['snippet']['title']\n",
    "            video_id = curr_vid['id']['videoId']\n",
    "            channel_id = curr_vid['snippet']['channelId']\n",
    "            published_at = curr_vid['snippet']['publishedAt']\n",
    "            video_dict = {\n",
    "                \"video_id\": video_id,\n",
    "                \"video_title\": video_title,\n",
    "                \"channel_id\": channel_id,\n",
    "                'published_at': published_at\n",
    "            }\n",
    "            \n",
    "            video_list.append(video_dict)\n",
    "    \n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(video_list)\n",
    "    print(f\"LENGTH OF VIDEO LIST: {len(video_list)}\")\n",
    "    print(f\"LENGTH OF VIDEO df: {results_df.shape}\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "results_df = scrape_youtube_df(\"Why I quit my analyst job\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0ad4d0-fc7c-40b3-a858-e7ce0d583132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>published_at</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>Category</th>\n",
       "      <th>favourites</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bVJfQAe-UP4</td>\n",
       "      <td>2022-12-20T12:00:33Z</td>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>Education</td>\n",
       "      <td>0</td>\n",
       "      <td>Why I Quit my 125k Analytics Job</td>\n",
       "      <td>158087</td>\n",
       "      <td>8715</td>\n",
       "      <td>Not available</td>\n",
       "      <td>858</td>\n",
       "      <td>This is not where I saw my career going, but h...</td>\n",
       "      <td>[Data Analyst, Data Analyst job, Data Analyst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-ayEjbg0ZEc</td>\n",
       "      <td>2021-07-22T14:00:01Z</td>\n",
       "      <td>UChpxXPOP1xIq65mpNv-DclQ</td>\n",
       "      <td>NFTs Simplified</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>0</td>\n",
       "      <td>I QUIT MY JOB as a Financial Analyst to START ...</td>\n",
       "      <td>3968</td>\n",
       "      <td>211</td>\n",
       "      <td>Not available</td>\n",
       "      <td>61</td>\n",
       "      <td>I quit my job as a financial analyst to start ...</td>\n",
       "      <td>[should you quit your job, should i quit my jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9h0uhjdsOI</td>\n",
       "      <td>2022-03-07T17:43:04Z</td>\n",
       "      <td>UC0GmdVKZhMM3Rmielp4oVAA</td>\n",
       "      <td>Stefanovic</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>0</td>\n",
       "      <td>The REAL Reason I Quit My 6-Figure Data Analys...</td>\n",
       "      <td>70501</td>\n",
       "      <td>3421</td>\n",
       "      <td>Not available</td>\n",
       "      <td>204</td>\n",
       "      <td>Save 25% off Datacamp here:\\nhttps://www.datac...</td>\n",
       "      <td>No Tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sd5F1uR3tvA</td>\n",
       "      <td>2024-03-23T11:22:46Z</td>\n",
       "      <td>UCNXDU-8M1KFAWpFxmev8C-g</td>\n",
       "      <td>Jess Ramos</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>I quit my 6-figure Data Analyst job in 4 month...</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>No Tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M8md7_gyBy4</td>\n",
       "      <td>2022-01-17T10:58:08Z</td>\n",
       "      <td>UC0GmdVKZhMM3Rmielp4oVAA</td>\n",
       "      <td>Stefanovic</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>0</td>\n",
       "      <td>I QUIT my $170,000 Tech Job After Learning 3 L...</td>\n",
       "      <td>1011039</td>\n",
       "      <td>41165</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1875</td>\n",
       "      <td>Save 25% off Datacamp here:\\nhttps://datacamp....</td>\n",
       "      <td>[i quit my job, passive income, passive income...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id          published_at                channel_id  \\\n",
       "0  bVJfQAe-UP4  2022-12-20T12:00:33Z  UC7cs8q-gJRlGwj4A8OmCmXg   \n",
       "1  -ayEjbg0ZEc  2021-07-22T14:00:01Z  UChpxXPOP1xIq65mpNv-DclQ   \n",
       "2  C9h0uhjdsOI  2022-03-07T17:43:04Z  UC0GmdVKZhMM3Rmielp4oVAA   \n",
       "3  sd5F1uR3tvA  2024-03-23T11:22:46Z  UCNXDU-8M1KFAWpFxmev8C-g   \n",
       "4  M8md7_gyBy4  2022-01-17T10:58:08Z  UC0GmdVKZhMM3Rmielp4oVAA   \n",
       "\n",
       "       channel_name        Category favourites  \\\n",
       "0  Alex The Analyst       Education          0   \n",
       "1   NFTs Simplified  People & Blogs          0   \n",
       "2        Stefanovic  People & Blogs          0   \n",
       "3        Jess Ramos   Entertainment          0   \n",
       "4        Stefanovic  People & Blogs          0   \n",
       "\n",
       "                                               title    views  likes  \\\n",
       "0                   Why I Quit my 125k Analytics Job   158087   8715   \n",
       "1  I QUIT MY JOB as a Financial Analyst to START ...     3968    211   \n",
       "2  The REAL Reason I Quit My 6-Figure Data Analys...    70501   3421   \n",
       "3  I quit my 6-figure Data Analyst job in 4 month...       91      3   \n",
       "4  I QUIT my $170,000 Tech Job After Learning 3 L...  1011039  41165   \n",
       "\n",
       "        dislikes comment_count  \\\n",
       "0  Not available           858   \n",
       "1  Not available            61   \n",
       "2  Not available           204   \n",
       "3  Not available             0   \n",
       "4  Not available          1875   \n",
       "\n",
       "                                         description  \\\n",
       "0  This is not where I saw my career going, but h...   \n",
       "1  I quit my job as a financial analyst to start ...   \n",
       "2  Save 25% off Datacamp here:\\nhttps://www.datac...   \n",
       "3                                                      \n",
       "4  Save 25% off Datacamp here:\\nhttps://datacamp....   \n",
       "\n",
       "                                                tags  \n",
       "0  [Data Analyst, Data Analyst job, Data Analyst ...  \n",
       "1  [should you quit your job, should i quit my jo...  \n",
       "2                                            No Tags  \n",
       "3                                            No Tags  \n",
       "4  [i quit my job, passive income, passive income...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_stats_df(input_df):\n",
    "    \"\"\"\n",
    "    Returns a modified version of input_df - added stats information columns.\n",
    "\n",
    "    Assume there is a column for 'video_ids' (ex: 'bVJfQAe-UP4')\n",
    "    \n",
    "    \"\"\"\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n",
    "    i = 0\n",
    "    stats_list = []\n",
    "    for curr_id in input_df['video_id']:       \n",
    "        stats = youtube.videos().list(\n",
    "            part='statistics, snippet',\n",
    "            id=curr_id).execute()\n",
    "        curr_channel_id = stats['items'][0]['snippet']['channelId']\n",
    "        curr_channel_name = stats['items'][0]['snippet']['channelTitle']\n",
    "        curr_cat = int(stats['items'][0]['snippet']['categoryId'])\n",
    "        curr_favs= stats['items'][0]['statistics']['favoriteCount']\n",
    "        #Check for view count, dislike count, like count, comment count integers \n",
    "        try:\n",
    "            curr_views = stats['items'][0]['statistics']['viewCount']\n",
    "        except:\n",
    "            curr_views = \"Not available\"\n",
    "        try:\n",
    "            curr_likes = stats['items'][0]['statistics']['likeCount']\n",
    "        except:\n",
    "            curr_likes = \"Not available\"\n",
    "        try:\n",
    "            curr_dislikes = stats['items'][0]['statistics']['dislikeCount']    \n",
    "        except:\n",
    "            curr_dislikes = \"Not available\"\n",
    "            \n",
    "        if 'commentCount' in stats['items'][0]['statistics'].keys():\n",
    "            curr_comments = stats['items'][0]['statistics']['commentCount']\n",
    "        else:\n",
    "            curr_comments = 0\n",
    "    \n",
    "        \n",
    "        #Check for tags, description, comments strings - If statements since they won't show up in snippet keys if not available\n",
    "        if 'tags' in stats['items'][0]['snippet'].keys():\n",
    "            curr_tags = stats['items'][0]['snippet']['tags']\n",
    "        else:\n",
    "            curr_tags = 'No Tags'\n",
    "        if 'description' in stats['items'][0]['snippet'].keys():\n",
    "            curr_description = stats['items'][0]['snippet']['description']\n",
    "        else:\n",
    "            curr_description = \"No Description\"\n",
    "    \n",
    "        #Write final dictionary\n",
    "        stats_dict = {\n",
    "            \"video_id\": curr_id,\n",
    "            \"published_at\": stats['items'][0]['snippet']['publishedAt'],\n",
    "            \"channel_id\": curr_channel_id,\n",
    "            \"channel_name\": curr_channel_name,\n",
    "            \"Category\": cat_dict[curr_cat], #cat is returned as an ind, put into the cat_dict\n",
    "            \"favourites\": curr_favs,\n",
    "            \"title\": stats['items'][0]['snippet']['title'],\n",
    "            \"views\": curr_views,\n",
    "            \"likes\": curr_likes,\n",
    "            'dislikes': curr_dislikes,\n",
    "            'comment_count': curr_comments,\n",
    "            \"description\": curr_description,\n",
    "            \"tags\": curr_tags\n",
    "        }\n",
    "        stats_list.append(stats_dict)\n",
    "        #### CHECK PRINTS\n",
    "        # print(stats_dict.keys())\n",
    "        # print(\"---\")\n",
    "        # i += 1\n",
    "        # if i == 5:\n",
    "        #     break\n",
    "    stats_df = pd.DataFrame.from_dict(stats_list)\n",
    "    return stats_df\n",
    "\n",
    "stats_df = create_stats_df(results_df)\n",
    "\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61a904c-60d8-4e11-b3ab-8fbd3ac9f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filepath = f\"{data_folder}/01_youtube_stats_df.csv\"\n",
    "stats_df.to_csv(out_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d616dd9-4a28-411f-a935-9e5d5c6bc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONALIZED ALL UNDER ALREADY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225be9a-145b-4046-9c6f-2e4e1e56c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IGNORE - ALREADY ADDED TO FUNCTION\n",
    "# ### ### VERSION 2 - MAIN SEARCH FOR PAGES OF RESULTS (Google API)\n",
    "# #### Use youtube.Search().list() to iterate through pages to get a list of responses\n",
    "# #### Test the iteration through the search results\n",
    "# #### 50 is the number of search results for each page - get number of iterations to go through\n",
    "\n",
    "\n",
    "# n_results = 0\n",
    "# n_iterations = max_results // 50 # get whole number of times we need to go through pages of youtube searches -\n",
    "# print(f\"n iterations: {n_iterations}\")\n",
    "\n",
    "# ### Initialize list of pages of results prior to searches\n",
    "# results_list = []\n",
    "# next_token = None\n",
    "# prev_token = None\n",
    "\n",
    "# for i in range(0, n_iterations):\n",
    "#     ### TEST OUTPUT - NEXT 2 LINES\n",
    "#     # print(f\"iteration {i}\")\n",
    "#     # print(f\"TOKENS BEFORE: {next_token} and {prev_token}\")\n",
    "\n",
    "#     #Main Google API search - go through current page's results, append to results_list\n",
    "#     #individual results are stored in results_list[i]['items']\n",
    "#     search_response = youtube.search().list(\n",
    "#         q=query, pageToken=next_token,\n",
    "#         maxResults=50, #only 50 results per page - verify?\n",
    "#         type=\"video\", order = \"relevance\", part=\"id, snippet\", location=None,locationRadius=None\n",
    "#     ).execute()\n",
    "#     results_list.append(search_response)\n",
    "    \n",
    "#     #Update next_token and prev_token variables for next search iteration\n",
    "#     if 'nextPageToken' in search_response.keys():\n",
    "#         next_token=search_response['nextPageToken']\n",
    "#     else:\n",
    "#         next_token=None\n",
    "#     if 'prevPageToken' in search_response.keys():\n",
    "#         prev_token=search_response['prevPageToken']\n",
    "#     else:\n",
    "#         prev_token=None\n",
    "        \n",
    "#     ### TEST OUTPUT - NEXT 4 LINES\n",
    "#     # print(f\"TOKENS AFTER: {next_token} and {prev_token}\")\n",
    "#     # print(f\"Iteration: {i}\")\n",
    "#     # print(f\"response length: {len(results_list)}\")\n",
    "#     # print(\"----\")\n",
    "# results_list[0]['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00f085-db8f-4087-abc2-f024b6decc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE OF RESULTS: \n",
    "\n",
    "### First page: results_list[0]['items']\n",
    "# [{'kind': 'youtube#searchResult',\n",
    "#   'etag': 'ZV8Ot8a1VIuZnYJCLRbqu8hZvOM',\n",
    "#   'id': {'kind': 'youtube#video', 'videoId': 'NErXzkS_qBc'},\n",
    "#   'snippet': {'publishedAt': '2024-01-29T16:00:41Z',\n",
    "#    'channelId': 'UCLCW9rn6lwZOHDnPnrWGTDA',\n",
    "#    'title': 'Today I Quit My Job... A Rant On Mental Heath In A Toxic Workplace...',\n",
    "#    'description': 'Today I quit my job. In this raw and honest video, I share the experience that led to this decision, where my manager dismissed the ...',\n",
    "#    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/NErXzkS_qBc/default.jpg',\n",
    "#      'width': 120,\n",
    "#      'height': 90},\n",
    "#     'medium': {'url': 'https://i.ytimg.com/vi/NErXzkS_qBc/mqdefault.jpg',\n",
    "#      'width': 320,\n",
    "#      'height': 180},\n",
    "#     'high': {'url': 'https://i.ytimg.com/vi/NErXzkS_qBc/hqdefault.jpg',\n",
    "#      'width': 480,\n",
    "#      'height': 360}},\n",
    "#    'channelTitle': 'Mims Films',\n",
    "#    'liveBroadcastContent': 'none',\n",
    "#    'publishTime': '2024-01-29T16:00:41Z'}},\n",
    "#  {'kind': 'youtube#searchResult',\n",
    "#   'etag': 'lGeetA0UG8yWph-kCyj3zkxnADY',\n",
    "#   'id': {'kind': 'youtube#video', 'videoId': 'UxC9AyKQ65w'},\n",
    "# .............\n",
    "\n",
    "\n",
    "### Last result of first page: results_list[0]['items'][49]\n",
    "# {'kind': 'youtube#searchResult',\n",
    "#  'etag': 'P_4ewemOuR5GKLgPmbwsKH11yQk',\n",
    "#  'id': {'kind': 'youtube#video', 'videoId': 'N94EpLXFbEM'},\n",
    "#  'snippet': {'publishedAt': '2024-12-15T16:00:25Z',\n",
    "#   'channelId': 'UC9lApmbeXQD_Uu_XNN5Rqsw',\n",
    "#   'title': 'I quit my job at age 55 after learning this...',\n",
    "#   'description': \"At 55, I made the hardest and most freeing decision of my life: I quit my corporate job. In this video, I'll share the eye-opening ...\",\n",
    "#   'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/N94EpLXFbEM/default.jpg',\n",
    "#     'width': 120,\n",
    "#     'height': 90},\n",
    "#    'medium': {'url': 'https://i.ytimg.com/vi/N94EpLXFbEM/mqdefault.jpg',\n",
    "#     'width': 320,\n",
    "#     'height': 180},\n",
    "#    'high': {'url': 'https://i.ytimg.com/vi/N94EpLXFbEM/hqdefault.jpg',\n",
    "#     'width': 480,\n",
    "#     'height': 360}},\n",
    "#   'channelTitle': 'reggi sweat',\n",
    "#   'liveBroadcastContent': 'none',\n",
    "#   'publishTime': '2024-12-15T16:00:25Z'}}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE\n",
    "\n",
    "#response list is a list of dictionaries - 'items' stores individual video info\n",
    "#responses_list[0]['items'][0]\n",
    "# responses_list[0]\n",
    "# responses_list[0]['items'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE\n",
    "# for response in responses_list:\n",
    "#     print(response.keys())\n",
    "#     for key in response.keys():\n",
    "\n",
    "#         print(response['items'])\n",
    "#         if key ==\"items\":\n",
    "#             item_list = response['items']\n",
    "#             for item in item_list:\n",
    "#                 video_dict = {}\n",
    "#     #             print(item)\n",
    "#                 title=item['snippet']['title']\n",
    "\n",
    "#                 desc = item['snippet']['description']\n",
    "#                 video_id = item['id']['videoId']\n",
    "#                 channel_id = items['snippet']['channelId']\n",
    "#                 print(desc)\n",
    "\n",
    "#         print(\"____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86564f3f-fcbe-46ab-89f0-a257d5ce600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IGNORE - ALREADY ADDED TO FUNCTION\n",
    "# ### VERSION 2 - GET RESULTS INTO DF\n",
    "# ### Is this necessary? just need the video IDs to create the next df\n",
    "# ### Or combine with youtube stats df\n",
    "# ### Create list of video information: video title, video id, channel ID, published time\n",
    "# ### Output: list of dictionaries containing video title, id, channel id, publish date of each \n",
    "# video_list = []\n",
    "\n",
    "# for result in results_list:\n",
    "#     curr_page = result['items']\n",
    "#     for curr_vid in curr_page:\n",
    "#         video_title=curr_vid['snippet']['title']\n",
    "#         video_id = curr_vid['id']['videoId']\n",
    "#         channel_id = curr_vid['snippet']['channelId']\n",
    "#         published_at = curr_vid['snippet']['publishedAt']\n",
    "#         video_dict = {\n",
    "#             \"video_id\": video_id,\n",
    "#             \"video_title\": video_title,\n",
    "#             \"channel_id\": channel_id,\n",
    "#             'published_at': published_at\n",
    "#         }\n",
    "        \n",
    "#         video_list.append(video_dict)\n",
    "\n",
    "\n",
    "# results_df = pd.DataFrame.from_dict(video_list)\n",
    "# print(f\"LENGTH OF VIDEO LIST: {len(video_list)}\")\n",
    "# print(f\"LENGTH OF VIDEO df: {results_df.shape}\")\n",
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3038a-bf87-4284-8d26-04cd6a292f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IGNORE - ADDED TO FUNCTIONS\n",
    "# ### VERSION 2: WORKING\n",
    "# ### Creates the stats_df: replaces the video_df by including view count info, tags, etc\n",
    "\n",
    "# i = 0\n",
    "# stats_list = []\n",
    "# for curr_id in results_df['video_id']:\n",
    "#     # print(curr_id)\n",
    "    \n",
    "#     stats = youtube.videos().list(\n",
    "#         part='statistics, snippet',\n",
    "#         id=curr_id).execute()\n",
    "#     # print(stats['items'][0]['snippet'].keys())\n",
    "#     # print(stats['items'][0]['statistics'].keys())\n",
    "#     curr_channel_id = stats['items'][0]['snippet']['channelId']\n",
    "#     curr_channel_name = stats['items'][0]['snippet']['channelTitle']\n",
    "#     curr_cat = int(stats['items'][0]['snippet']['categoryId'])\n",
    "#     curr_favs= stats['items'][0]['statistics']['favoriteCount']\n",
    "#     #Check for view count, dislike count, like count, comment count integers \n",
    "#     try:\n",
    "#         curr_views = stats['items'][0]['statistics']['viewCount']\n",
    "#     except:\n",
    "#         curr_views = \"Not available\"\n",
    "#     try:\n",
    "#         curr_likes = stats['items'][0]['statistics']['likeCount']\n",
    "#     except:\n",
    "#         curr_likes = \"Not available\"\n",
    "#     try:\n",
    "#         curr_dislikes = stats['items'][0]['statistics']['dislikeCount']    \n",
    "#     except:\n",
    "#         curr_dislikes = \"Not available\"\n",
    "        \n",
    "#     if 'commentCount' in stats['items'][0]['statistics'].keys():\n",
    "#         curr_comments = stats['items'][0]['statistics']['commentCount']\n",
    "#     else:\n",
    "#         curr_comments = 0\n",
    "\n",
    "    \n",
    "#     #Check for tags, description, comments strings - If statements since they won't show up in snippet keys if not available\n",
    "#     if 'tags' in stats['items'][0]['snippet'].keys():\n",
    "#         curr_tags = stats['items'][0]['snippet']['tags']\n",
    "#     else:\n",
    "#         curr_tags = 'No Tags'\n",
    "#     if 'description' in stats['items'][0]['snippet'].keys():\n",
    "#         curr_description = stats['items'][0]['snippet']['description']\n",
    "#     else:\n",
    "#         curr_description = \"No Description\"\n",
    "\n",
    "#     #Write final dictionary\n",
    "#     stats_dict = {\n",
    "#         \"video_id\": curr_id,\n",
    "#         \"published_at\": stats['items'][0]['snippet']['publishedAt'],\n",
    "        \n",
    "#         \"channel_id\": curr_channel_id,\n",
    "#         \"channel_name\": curr_channel_name,\n",
    "#         \"Category\": cat_dict[curr_cat], #cat is returned as an ind, put into the cat_dict\n",
    "#         \"favourites\": curr_favs,\n",
    "#         \"title\": stats['items'][0]['snippet']['title'],\n",
    "#         \"views\": curr_views,\n",
    "#         \"likes\": curr_likes,\n",
    "#         'dislikes': curr_dislikes,\n",
    "#         'comment_count': curr_comments,\n",
    "#         \"description\": curr_description,\n",
    "#         \"tags\": curr_tags\n",
    "\n",
    "#         # \"tags\": stats['items'][0]['snippet']['tags'],\n",
    "#         # \"category_id\": stats['items'[0]['snippet']['categoryId'],\n",
    "#         # \"view_count\": stats['items'][0]['statistics']['viewCount']\n",
    "#     }\n",
    "#     stats_list.append(stats_dict)\n",
    "#     #### CHECK PRINTS\n",
    "#     # print(stats_dict.keys())\n",
    "#     # print(\"---\")\n",
    "#     # i += 1\n",
    "#     # if i == 5:\n",
    "#     #     break\n",
    "# stats_list\n",
    "# stats_df = pd.DataFrame.from_dict(stats_list)\n",
    "# stats_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1ce84-ec95-4fce-970f-1e9e8eeb1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### OBSOLETE\n",
    "\n",
    "# #Create individual lists and store items from video_list dictionaries\n",
    "\n",
    "# title = []\n",
    "# channelId = []\n",
    "# channelTitle = []\n",
    "# categoryId = []\n",
    "# publishedAt=[]\n",
    "# videoId = []\n",
    "# viewCount = []\n",
    "# likeCount = []\n",
    "# dislikeCount = []\n",
    "# commentCount = []\n",
    "# favoriteCount = []\n",
    "# category = []\n",
    "# tags = []\n",
    "# videos = []\n",
    "# descriptions=[]\n",
    "# i = 0\n",
    "# for video in video_list:\n",
    "#     if i % 100 == 0:\n",
    "#         print(\"VIDEOS PROCESSED: \", i)\n",
    "#     videoId.append(video['videoId'])\n",
    "#     title.append(video['videoTitle'])\n",
    "#     publishedAt.append(video['publishedAt'])\n",
    "#     stats = youtube.videos().list(\n",
    "#         part='statistics, snippet',\n",
    "#         id=video['videoId']).execute()\n",
    "#     channelId.append(stats['items'][0]['snippet']['channelId']) \n",
    "#     channelTitle.append(stats['items'][0]['snippet']['channelTitle']) \n",
    "#     categoryId.append(stats['items'][0]['snippet']['categoryId']) \n",
    "#     favoriteCount.append(stats['items'][0]['statistics']['favoriteCount'])\n",
    "#     try:\n",
    "#         viewCount.append(stats['items'][0]['statistics']['viewCount']) \n",
    "#     except:\n",
    "#         viewCount.append(\"Not available\") \n",
    "#     #Not every video has likes/dislikes enabled so they won't appear in JSON response\n",
    "#     try:\n",
    "#         likeCount.append(stats['items'][0]['statistics']['likeCount'])\n",
    "#     except:\n",
    "#    #Good to be aware of Channels that turn off their Likes\n",
    "# #         print(\"Video titled {0}, on Channel {1} Likes Count is not available\".format(stats['items'][0]['snippet']['title'],\n",
    "# #                                                                                      stats['items'][0]['snippet']['channelTitle']))\n",
    "# #         print(stats['items'][0]['statistics'].keys())\n",
    "#     #Appends \"Not Available\" to keep dictionary values aligned\n",
    "#         likeCount.append(\"Not available\")\n",
    "\n",
    "#     try:\n",
    "#         dislikeCount.append(stats['items'][0]['statistics']['dislikeCount'])     \n",
    "#     except:\n",
    "#         #Good to be aware of Channels that turn off their Likes\n",
    "# #         print(\"Video titled {0}, on Channel {1} Dislikes Count is not available\".format(stats['items'][0]['snippet']['title'],\n",
    "# #                                                                                         stats['items'][0]['snippet']['channelTitle']))\n",
    "# #         print(stats['items'][0]['statistics'].keys())\n",
    "#         dislikeCount.append(\"Not available\")\n",
    "\n",
    "#     if 'commentCount' in stats['items'][0]['statistics'].keys():\n",
    "#         commentCount.append(stats['items'][0]['statistics']['commentCount'])\n",
    "#     else:\n",
    "#         commentCount.append(0)\n",
    "\n",
    "#     if 'tags' in stats['items'][0]['snippet'].keys():\n",
    "#         tags.append(stats['items'][0]['snippet']['tags'])\n",
    "#     else:\n",
    "#         tags.append(\"No Tags\")\n",
    "        \n",
    "#     if 'description' in stats['items'][0]['snippet'].keys():\n",
    "#         descriptions.append(stats['items'][0]['snippet']['description'])\n",
    "#     else:\n",
    "#         #I'm not a fan of empty fields\n",
    "#         tags.append(\"No Description\")\n",
    "    \n",
    "#     #a given video is equivelant to stats['items'][0]\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c461e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE - \n",
    "\n",
    "# #create list of ids to iterate through - remove the layer of lists given for individual queries of youtube.search()\n",
    "\n",
    "# video_list = []\n",
    "# for response in responses_list:\n",
    "# #     print(response.keys())\n",
    "#     videos_list = response['items']\n",
    "#     for item in videos_list:\n",
    "        \n",
    "#         video_title=item['snippet']['title']\n",
    "# #         desc = item['snippet']['description'] #only gives snippet of desc - add when getting transcripts\n",
    "#         video_id = item['id']['videoId']\n",
    "#         channel_id = item['snippet']['channelId']\n",
    "#         published_at = item['snippet']['publishedAt']\n",
    "#         video_dict = {\n",
    "#             \"videoId\": video_id,\n",
    "#             \"videoTitle\": video_title,\n",
    "#             \"channelId\": channel_id,\n",
    "#             'publishedAt': published_at\n",
    "#         }\n",
    "        \n",
    "#         video_list.append(video_dict)\n",
    "# len(video_list)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f4fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE\n",
    "\n",
    "# #write JSON to store video information for all\n",
    "# youtube_dict = {'tags':tags,'channelId': channelId,'channelTitle': channelTitle,\n",
    "#                 'categoryId':categoryId,'publishedAt': publishedAt,'title':title,'videoId':videoId,\n",
    "#                 'viewCount':viewCount,'likeCount':likeCount,'dislikeCount':dislikeCount,\n",
    "#                 'commentCount':commentCount,'favoriteCount':favoriteCount,\n",
    "#                \"description\": descriptions}\n",
    "\n",
    "# # for key in youtube_dict.keys():\n",
    "# #     print(key)\n",
    "# #     print(\"LENGTH: \", len(youtube_dict[key]))\n",
    "# #     print(youtube_dict[key][:5])\n",
    "    \n",
    "# #     print(\"---\")\n",
    "# youtube_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bcd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0192cf-7867-4e5f-bc0b-4832a1b5db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_filepath = f\"{data_folder}/01_youtube_stats_df.csv\"\n",
    "# stats_df.to_csv(out_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_id = \"PgfzN1xfgLc\"\n",
    "# YouTubeTranscriptApi.get_transcript(test_id,languages=['en'])\n",
    "\n",
    "# for i, video_id in enumerate(youtube_dict['videoId']):\n",
    "#      print(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce244f84-b556-42eb-bbd7-dbaae8642eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip freeze | grep youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce7a66-cb1a-4ffd-b2d1-a660404c4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MOVE TRANSCRIPT SCRAPE TO NEXT ONE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267a629-5338-4489-bb4e-1c6260047763",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING - IGNORE\n",
    "# test_id = \"sNVcTgLAX4g\"\n",
    "# from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# ytt_api = YouTubeTranscriptApi()\n",
    "# eng_transcript = ytt_api.get_transcript(test_id, languages = ['en'])\n",
    "# transcript_sentlist = [str(x['text']).replace(\"\\xa0\", \"\") for x in eng_transcript]\n",
    "# \" \".join(transcript_sentlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576375c-bf45-458c-b624-9a03be01f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### WORKING - MOVED TO 02 ALREADY\n",
    "##Get transcripts using get_transcript() of YoutubeTranscriptApi for each transcript\n",
    "### Get as dictionary of dictionary: youtube_id : {}\n",
    "# transcript_dict = {}\n",
    "# yt_api = YouTubeTranscriptApi()\n",
    "\n",
    "# for i, video_id in enumerate(stats_df['video_id']):\n",
    "#     transcript_sents = None #create new list for individual sentences\n",
    "#     try:\n",
    "#         curr_result = yt_api.get_transcript(video_id,languages=['en'])\n",
    "#         transcript_sents = [str(x['text']).replace(\"\\xa0\", \"\") for x in curr_result]\n",
    "#         transcript_joined = \" \".join(transcript_sentlist)\n",
    "#         # print(f\"FIRST SENTS FOR {video_id} TRANSCRIPT: {transcript_sents[:5]}\")\n",
    "        \n",
    "        \n",
    "#     except:\n",
    "#         print(f\"NO TRANSCRIPT FOR {video_id} - SKIPPED\")\n",
    "#     transcript_dict[video_id] = {\n",
    "#                                     \"joined\": transcript_joined,\n",
    "#                                     \"sents\": transcript_sents\n",
    "        \n",
    "#                                 }\n",
    "    \n",
    "#     if i % 50 == 0:\n",
    "#         print(f\"PROCESSED {i} TRANSCRIPTS\")\n",
    "#         print(f\"LENGTH OF DICTS\")\n",
    "\n",
    "# print(len(transcript_dict))\n",
    "    \n",
    "# for curr_key in transcript_dict.keys():\n",
    "#     try:\n",
    "#         print(f\"youtube_id: {curr_key}, number of sents: {len(transcript_dict[curr_key]['sents'])}\")\n",
    "#     except:\n",
    "#         print(f\"TRANSCRIPT MISSING FOR {curr_key}\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc1ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"and I've tried asking God I said God\", 'start': 0.0, 'duration': 4.74}, {'text': 'what exactly is this next season gonna', 'start': 2.159, 'duration': 5.22}, {'text': 'look like can you give me a Five-Year', 'start': 4.74, 'duration': 5.399}, {'text': \"Plan of How It's all gonna play out and\", 'start': 7.379, 'duration': 4.501}, {'text': \"God said girl you know that's not how it\", 'start': 10.139, 'duration': 3.721}]\n",
      "tq4No1cOwZM\n",
      "[{'text': 'so in 2020 I quite quit my job and it', 'start': 0.0, 'duration': 5.16}, {'text': 'was without a doubt the best decision of', 'start': 2.58, 'duration': 4.38}, {'text': \"my life and since then I've created\", 'start': 5.16, 'duration': 3.479}, {'text': 'several online businesses and became', 'start': 6.96, 'duration': 3.36}, {'text': 'financially free but before I tell you', 'start': 8.639, 'duration': 3.781}]\n",
      "nj2c5mKGTtQ\n",
      "[{'text': 'Translator: Valérie ESPANET\\nReviewer: Zsófia Herczeg', 'start': 0.0, 'duration': 7.0}, {'text': 'Imagine for a moment', 'start': 8.88, 'duration': 2.721}, {'text': \"that you're miserable at work,\", 'start': 11.971, 'duration': 1.94}, {'text': \"and you're thinking about quitting.\", 'start': 14.171, 'duration': 2.005}, {'text': \"But you're really good at your job.\", 'start': 17.126, 'duration': 2.26}]\n",
      "Rw7TWQ-Rt2Q\n",
      "[{'text': \"When you're fed up with your job,\", 'start': 0.0, 'duration': 1.748}, {'text': 'it can be tempting to do\\nsomething big and dramatic.', 'start': 1.789, 'duration': 4.004}, {'text': 'To yell, \"I quit!\" during\\na meeting and peace out,', 'start': 5.793, 'duration': 2.962}, {'text': 'or post a video on social media\\ncalling out your former employer.', 'start': 8.755, 'duration': 3.545}, {'text': 'But quitting well can actually\\nbe an opportunity for growth.', 'start': 12.341, 'duration': 3.754}]\n",
      "QD-k5c9lX24\n",
      "NONE\n",
      "MHJjDo1lvpI\n",
      "[{'text': \"Hey cultivator. Welcome back\\nto my channel in today's video.\", 'start': 0.12, 'duration': 3.12}, {'text': 'I want to answer a question I see come\\nup at least once a week inside of my', 'start': 3.241, 'duration': 3.959}, {'text': 'private Facebook group, cultivate\\nyour career, which by the way,', 'start': 7.201, 'duration': 3.119}, {'text': 'is linked down below\\nin the description box.', 'start': 10.321, 'duration': 1.919}, {'text': 'It is a free community of likeminded\\ncorporate professionals who are really', 'start': 12.42, 'duration': 4.59}]\n",
      "JgLYxnI_7c8\n",
      "[{'text': \"in this video i'm going to share how i\", 'start': 0.16, 'duration': 4.24}, {'text': 'started my youtube channel how i was', 'start': 2.32, 'duration': 4.64}, {'text': 'able to grow it and monetize it and how', 'start': 4.4, 'duration': 4.64}, {'text': 'i was able to use youtube to quit my', 'start': 6.96, 'duration': 3.39}, {'text': 'nine to five job', 'start': 9.04, 'duration': 5.44}]\n",
      "amXKuRMs9Aw\n",
      "[{'text': 'i worked with clinical clients a lot you', 'start': 0.0, 'duration': 2.72}, {'text': 'know', 'start': 2.08, 'duration': 2.56}, {'text': 'in career counseling and one of the', 'start': 2.72, 'duration': 4.88}, {'text': \"things we'd analyzed right away was well\", 'start': 4.64, 'duration': 5.52}, {'text': 'can you actually do your job well and be', 'start': 7.6, 'duration': 4.88}]\n",
      "TTqp56FK55k\n",
      "[{'text': '- Well, it happened.', 'start': 0.12, 'duration': 0.94}, {'text': 'I quit my job to pursue a lifelong dream', 'start': 1.06, 'duration': 2.44}, {'text': 'of becoming an extra on the next season', 'start': 3.5, 'duration': 2.28}, {'text': 'of \"The Mandalorian.\"', 'start': 5.78, 'duration': 0.833}, {'text': 'This is the way.', 'start': 6.613, 'duration': 1.137}]\n",
      "scLNmepsi98\n",
      "[{'text': \"hey guys what's up my name is Ashley\", 'start': 0.359, 'duration': 4.681}, {'text': 'Kooiman and I wanted to take a little', 'start': 2.58, 'duration': 4.92}, {'text': 'time to explain to you guys a little bit', 'start': 5.04, 'duration': 5.46}, {'text': 'more in detail how I budgeted how I came', 'start': 7.5, 'duration': 4.86}, {'text': 'up with the idea what triggered this', 'start': 10.5, 'duration': 4.799}]\n",
      "u5YfJV12Xyo\n",
      "[{'text': \"so there's a new phenomenon ladies and\", 'start': 0.16, 'duration': 4.8}, {'text': 'gentlemen sweeping through workplaces', 'start': 2.32, 'duration': 5.599}, {'text': \"across the country and it's called quiet\", 'start': 4.96, 'duration': 4.08}, {'text': 'quitting', 'start': 7.919, 'duration': 2.72}, {'text': \"i don't know if you've heard of it\", 'start': 9.04, 'duration': 3.44}]\n",
      "y1kb1go1zao\n",
      "[{'text': \"I'm literally six months into my first\", 'start': 0.0, 'duration': 5.16}, {'text': 'corporate job and I already want to quit', 'start': 2.58, 'duration': 4.679}, {'text': 'so the Creator goes on to talk about how', 'start': 5.16, 'duration': 4.439}, {'text': 'at face value that job is amazing she', 'start': 7.259, 'duration': 3.901}, {'text': 'loves her co-workers why does she still', 'start': 9.599, 'duration': 3.061}]\n",
      "_BHA_X1yHKA\n",
      "[{'text': 'foreign', 'start': 0.0, 'duration': 17.84}, {'text': '[Music]', 'start': 1.23, 'duration': 19.35}, {'text': \"what's up welcome back to my channel so\", 'start': 17.84, 'duration': 6.699}, {'text': \"today I'm creating my job it's a little\", 'start': 20.58, 'duration': 5.699}, {'text': \"nerve-wracking but I've wanted to do it\", 'start': 24.539, 'duration': 3.601}]\n",
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# ## OBSOLETE \n",
    "# transcripts_sents = []\n",
    "# transcripts_strings = []\n",
    "# transcripts_parsed = []\n",
    "# for i, video_id in enumerate(youtube_dict['videoId']):\n",
    "# #     print(video_id)\n",
    "#     transcript_sentlist = []\n",
    "#     try:\n",
    "#         eng_transcript = YouTubeTranscriptApi.get_transcript(video_id,languages=['en'])\n",
    "# #         print(eng_transcript[0:5])\n",
    "#         transcript_sentlist = [str(x['text']).replace(\"\\xa0\", \"\") for x in eng_transcript]\n",
    "#         transcript_joined = \" \".join(transcript_sentlist)\n",
    "#         #transcript_sentlist is broken up by timestamp - use Spacy to break up using dependancy parse\n",
    "# #         document = nlp(transcript_joined)\n",
    "# #         transcript_parsed = [x for x in document.sents]\n",
    "#     except:\n",
    "# #         print(\"NONE\")\n",
    "#         transtript_sentlist = None\n",
    "#         transcript_joined = None\n",
    "# #         transcript_parsed = None\n",
    "# #         pass\n",
    "#     transcripts_sents.append(transcript_sentlist)\n",
    "#     transcripts_strings.append(transcript_joined)\n",
    "# #     transcripts_parsed.append(transcript_parsed)\n",
    "#     if i % 25 ==0:\n",
    "#         print(f\"PROCESSED: {i}\")\n",
    "# #         break\n",
    "# print(f\"COMPLETED\")\n",
    "# youtube_dict['transcripts_raw'] = transcripts_sents\n",
    "# youtube_dict['transcript_strings'] = transcripts_strings\n",
    "# # youtube_dict['transcript_parsed'] = transcripts_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de154145",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OBSOLETE:\n",
    "### search Youtube, iterate through pages and get list of responses\n",
    "###OUT: response_list: list of dictionaries\n",
    "#use youtube.search().list(part='id, snippet')\n",
    "\n",
    "\n",
    "# location=None\n",
    "# location_radius=None\n",
    "\n",
    "# responses_list =[]\n",
    "\n",
    "# for i in range(0,max_results,50):\n",
    "# #     print(i)\n",
    "    \n",
    "#     if i % 100 == 0:\n",
    "#         print(\"VIDEO STATS PROCESSED: \", i)\n",
    "#     if i ==0:\n",
    "#         next_token=None\n",
    "#         prev_token = None\n",
    "#     search_response = youtube.search().list(\n",
    "#         q=query,\n",
    "#         type=\"video\",\n",
    "#         pageToken=next_token,\n",
    "#         order = order,\n",
    "#         part=\"id,snippet\",\n",
    "#         maxResults=max_results,\n",
    "#         location=location,\n",
    "#         locationRadius=location_radius).execute()\n",
    "    \n",
    "#     responses_list.append(search_response)\n",
    "#     #GET NEXT PAGE OF RESULTS\n",
    "#     if 'nextPageToken' in search_response.keys():\n",
    "#         next_token=search_response['nextPageToken']\n",
    "#     else:\n",
    "#         next_token=None\n",
    "        \n",
    "#     if 'prevPageToken' in search_response.keys():\n",
    "#         prev_token=search_response['prevPageToken']\n",
    "#     else:\n",
    "#         prev_token=None\n",
    "\n",
    "# #     print(\"----\")\n",
    "\n",
    "\n",
    "# # print(responses_list[-1])\n",
    "# print(len(responses_list[0]['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_descs = [str(x) for x in youtube_dict['description']]\n",
    "# print(new_descs)\n",
    "# youtube_dict['description'] = new_descs\n",
    "\n",
    "# trans_parsed = []\n",
    "# for transcript_parsed in youtube_dict['transcript_parsed']:\n",
    "#     print(transcript_parsed)\n",
    "#     if transcript_parsed:\n",
    "#         new_parsed = [str(x) for x in transcript_parsed]\n",
    "#     else:\n",
    "#         new_parsed = None\n",
    "#     trans_parsed.append(new_parsed)\n",
    "# youtube_dict['transcript_parsed'] = trans_parsed\n",
    "# print(len(trans_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf92da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK VALUES CELL - COMMENT OUT WHEN RUNNING\n",
    "\n",
    "\n",
    "#     dict_item = youtube_dict[key][0]\n",
    "#     print(key)\n",
    "#     print(dict_item)\n",
    "#     print(type(dict_item))\n",
    "#     print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4763b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###ADD IN 02_PROCESS TRANSCRIPTS CODE\n",
    "# all_transcripts = []\n",
    "\n",
    "# id_list = youtube_dict['videoId']\n",
    "\n",
    "# for i, video_id in enumerate(youtube_dict['videoId']):\n",
    "    \n",
    "#     try:\n",
    "#         transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "#     except:\n",
    "#         transtript_list = None\n",
    "#         pass\n",
    "    \n",
    "#     all_transcripts.append(transcript_list)\n",
    "#     if not transcript_list:\n",
    "#         print(\"MISSING TRANSCRIPT:\", youtube_dict[\"title\"][i])\n",
    "    \n",
    "#     if i % 100 == 0:\n",
    "#         print(\"PROCESSED: \",i)\n",
    "        \n",
    "# youtube_dict['transcript_api'] = all_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9698183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e143e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(out_filepath, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(youtube_dict, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be53524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(youtube_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248336f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5678f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #REDO WITH ID AND TRANSCRIPT API IN ONE PLACE\n",
    "\n",
    "# transcript_dict_all = {}\n",
    "# transcript_dict_man = {}\n",
    "\n",
    "# for i, video_id in enumerate(youtube_dict['videoId']):\n",
    "    \n",
    "#     transcript_api = youtube_dict['transcript_api'][i]\n",
    "#     try:\n",
    "#         en_transcript = transcript_api.find_transcript(['en']).fetch()\n",
    "#         transcript_dict_all[video_id] = en_transcript\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "# #     #try to find a manual transcript if it exists in transcript_list - not often\n",
    "# #     try:\n",
    "# #         en_transcript_manual = transcript_api.find_manually_created_transcript(['en']).fetch()\n",
    "# #         transcript_dict_man[video_id] = en_transcript_manual\n",
    "# #     except:\n",
    "# #         pass\n",
    "    \n",
    "#     if i % 200 == 0:\n",
    "#         print(\"PROCESSED: \", i)\n",
    "#         print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transcript_dict_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa035f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_transcripts(raw_dict_in, outfile='processed_transcripts.json'):\n",
    "    \n",
    "#     \"\"\"Writes a json file from the raw transcript dict returned from scrape_transcripts()\n",
    "    \n",
    "#     Returns processed_transcripts with video_ids as keys and the following items:\n",
    "#         list: list of sentence strings from 'text' field of raw_dict\n",
    "#         str: combined string from 'text' field of raw_dict\n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "#     processed_transcripts = {}\n",
    "#     for video_id, transcript in raw_dict_in.items():\n",
    "#         processed_transcripts[video_id] = {\n",
    "#             \"list\": [],\n",
    "#             \"str\": \"\"\n",
    "#         }\n",
    "#         transcript_list = []\n",
    "#         transcript_str = \"\"\n",
    "#         for item in transcript:\n",
    "#             text_line = item['text']\n",
    "#             transcript_list.append(text_line)\n",
    "#             transcript_str += text_line \n",
    "#             transcript_str += \" \"\n",
    "#         processed_transcripts[video_id]['list'] = transcript_list\n",
    "#         processed_transcripts[video_id]['str'] = transcript_str\n",
    "        \n",
    "#         return processed_transcripts\n",
    "\n",
    "\n",
    "# #     with open(outfile, 'w', encoding='utf-8') as f:\n",
    "# #         json.dump(processed_transcripts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65fff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process_transcripts(transcript_dict_man, \"processed_MAN.json\")\n",
    "# process_transcripts(transcript_dict_all, \"processed_ALL.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f372252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use youtube.videos().list(part='statistics, snippet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775aeb69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
